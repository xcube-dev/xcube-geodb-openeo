{
 "cells": [
  {
   "cell_type": "markdown",
   "id": "ced119793a5f0f59",
   "metadata": {
    "collapsed": false
   },
   "source": [
    "# Demonstration of extended geoDB openEO backend capabilities + Use Case #2\n",
    "\n",
    "This notebook demonstrates how the extended capabilities of the geoDB openEO backend can be used in a real-world-like use case: data from a vector cube is (temporally) aggregated and used alongside with Sentinel-3 raster data. Apart from this main use case, additional capabilities of the geoDB openEO backend are shown.  \n",
    "\n",
    "### Preparations\n",
    "First, the openeo-client software is imported; it is used throughout the notebook to interact with the geoDB openEO backend. Then, the openeo client is used to open connections to the geoDB openEO backend and to the Copernicus Data Space Ecosystem backend, which provides the raster data used in this example."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "edcce2fdfc4a403a",
   "metadata": {},
   "outputs": [],
   "source": [
    "import openeo\n",
    "\n",
    "geodb_url = 'https://geodb.openeo.dev.brockmann-consult.de'\n",
    "geodb = openeo.connect(geodb_url)\n",
    "\n",
    "cdse_url = 'https://openeo.dataspace.copernicus.eu/'\n",
    "cdse = openeo.connect(cdse_url)\n",
    "cdse.authenticate_oidc()"
   ]
  },
  {
   "cell_type": "markdown",
   "source": [
    "### Load and aggregate vector data\n",
    "\n",
    "The following three lines demonstrate the aggregation capabilities of the geoDB openEO backend. Note that the whole process only starts as soon as the processing is triggered by the `download` command. First, the server is notified that the collection shall be loaded. In the second step, the collection is temporally aggregated. The three parameters of the `aggregate_temporal`- function are:\n",
    "1) `temporal intervals` (`[['2000-01-01', '2030-01-05']]`): all data that falls in these intervals are aggregated.\n",
    "2) `reducer` (`mean`): a 'reducer' function which aggregates the collected temporal data, i.e. computes a single value from a set of input values. Typical functions are `mean`, `median`, `std`, ...\n",
    "3) `context` (`{'pattern': '%Y-%M-%d'}`): any context; used here exemplarily to provide the date pattern  \n",
    "\n",
    "The collection is an artificial collection made for demo purposes. It is a cube of 8 features, containing population info for 4 different points in time, for two geometries (more or less Western and Eastern Hamburg):\n",
    "\n",
    "![openeo_pop_hamburg](images/openeo_pop_hamburg.png)\n"
   ],
   "metadata": {
    "collapsed": false
   },
   "id": "28a0857a424ccb9f"
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "7903b501d68f258c",
   "metadata": {
    "collapsed": false
   },
   "outputs": [],
   "source": [
    "hamburg = geodb.load_collection('openeo~pop_hamburg')\n",
    "hamburg = hamburg.aggregate_temporal([['2000-01-01', '2030-01-05']], 'mean', context={'pattern': '%Y-%M-%d'})\n",
    "hamburg.download('./hamburg_mean.json', 'GeoJSON')"
   ]
  },
  {
   "cell_type": "markdown",
   "source": [
    "### Prepare raster data\n",
    "\n",
    "Next, the CDSE openEO backend is used to load a small sample of OLCI L1 data. This data is used to compute the NDVI over the Hamburg area, temporally aggregating the first 5 days in 2020. This data will be used in conjunction with the vector data prepared above."
   ],
   "metadata": {
    "collapsed": false
   },
   "id": "792b5b8cdbb6178f"
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "ab0edbcf-c37d-4ccf-b533-70d8877c9419",
   "metadata": {},
   "outputs": [],
   "source": [
    "olci = cdse.load_collection(\"SENTINEL3_OLCI_L1B\",\n",
    "                            spatial_extent={\"west\": 9.7, \"south\": 53.3, \"east\": 10.3, \"north\": 53.8},\n",
    "                            temporal_extent=[\"2020-01-01\", \"2020-01-05\"],\n",
    "                            bands=[\"B08\", \"B17\"])\n",
    "\n",
    "olci_ndvi = olci.ndvi(nir=\"B17\", red=\"B08\")\n",
    "ndvi_temp_agg = olci_ndvi.aggregate_temporal([[\"2020-01-01T00:00:00.000Z\", \"2020-01-05T00:00:00.000Z\"]], 'median')"
   ]
  },
  {
   "cell_type": "markdown",
   "source": [
    "### Use the vector data for spatial aggregation of the raster data\n",
    "\n",
    "Now we use the vector data produced by the geoDB openEO backend to determine the geometries over which the NDVI data shall be extracted.\n",
    "As the job is pretty small, it will finish after a short while."
   ],
   "metadata": {
    "collapsed": false
   },
   "id": "947db26daf8b43ea"
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "f056401a-65de-48bd-9f73-1915ea47b14f",
   "metadata": {},
   "outputs": [],
   "source": [
    "import json\n",
    "with open('./hamburg_mean.json') as f:\n",
    "    geometries = json.load(f)\n",
    "ndvi_final = ndvi_temp_agg.aggregate_spatial(geometries, openeo.processes.ProcessBuilder.mean)\n",
    "result = ndvi_final.save_result(format = \"GTiff\")\n",
    "job = result.create_job()\n",
    "job.start_and_wait()"
   ]
  },
  {
   "cell_type": "markdown",
   "source": [
    "### Download the NDVI data, and prepare for visualisation\n",
    "\n",
    "In this step, the NDVI data we just produced are downloaded. It is a very small JSON file that simply contains the aggregated NDVI values for all the geometries of the vector cube `openeo~hamburg`. There are two of those, so the JSON file contains only two values."
   ],
   "metadata": {
    "collapsed": false
   },
   "id": "388fbe29e48c671"
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "1868c72e-cfb0-458b-82bf-a6e0b57e15d9",
   "metadata": {},
   "outputs": [],
   "source": [
    "result_file = job.get_results().download_files(\"output\")[0]\n",
    "with open(str(result_file)) as f:\n",
    "    aggregated_ndvi = json.load(f)\n",
    "ndvi = list([v[0] for v in aggregated_ndvi[list(aggregated_ndvi.keys())[0]]])"
   ]
  },
  {
   "cell_type": "markdown",
   "source": [
    "### Prepare the vector data for visualisation\n",
    "\n",
    "The vector data are openend as GeoDataFrame, which allows for visualisation. The NDVI data is added to the DataFrame, so the vector and (aggregated) raster data can be shown together.\n"
   ],
   "metadata": {
    "collapsed": false
   },
   "id": "27e94dedba9c05e6"
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "f17b7277-2b4a-40d4-b982-f51a0b57915c",
   "metadata": {},
   "outputs": [],
   "source": [
    "import geopandas\n",
    "gdf = geopandas.read_file('./hamburg_mean.json')\n",
    "gdf['ndvi'] = ndvi"
   ]
  },
  {
   "cell_type": "markdown",
   "source": [
    "### Visualise\n",
    "\n",
    "Finally, we draw the geometries on a map. The aggregated 'population' information that we have extracted from the geoDB openEO backend are displayed in an overlay. The colors represent the NDVI values we received from the CDSE openEO backend. \n"
   ],
   "metadata": {
    "collapsed": false
   },
   "id": "80f7404cfcf93fe"
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "2316d61c-261c-41af-8de6-a5aa30367d0b",
   "metadata": {
    "scrolled": true
   },
   "outputs": [],
   "source": [
    "import matplotlib.pyplot as plt\n",
    "gdf['color'] = ['#006400', '#90EE90']\n",
    "gdf.plot(legend=True, color=gdf['color'])\n",
    "va = ['bottom', 'top']\n",
    "for idx, row in gdf.iterrows():\n",
    "    coords = {0: (9.75, 53.65),\n",
    "              1: (10.03, 53.5)}\n",
    "    plt.annotate('average population 2000-2020:\\n' + str(int((row['population']))), xy=coords[idx],\n",
    "                 horizontalalignment='left', verticalalignment='top', backgroundcolor='b')\n",
    "for idx, row in gdf.iterrows():\n",
    "    coords = {0: (9.75, 53.585),\n",
    "              1: (10.03, 53.435)}\n",
    "    plt.annotate('average ndvi early 2020:\\n' + f'{row[\"ndvi\"]:.4f}', xy=coords[idx],\n",
    "                 horizontalalignment='left', verticalalignment='bottom', backgroundcolor='b') "
   ]
  },
  {
   "cell_type": "markdown",
   "source": [
    "### Math\n",
    "\n",
    "We can also do simple math on vector cubes provided by the geoDB openEO backend. In the following code, we define two functions (`apply_scaling`and `add_offset`), and apply those functions to the vector cube. We download the results and inspect the datacube. Only those data to which the functions can be applied to are scaled: `population` has been scaled, but `id`, `geometry`, and `date` are left untouched.\n"
   ],
   "metadata": {
    "collapsed": false
   },
   "id": "8f2bdc321f91ac9e"
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "outputs": [],
   "source": [
    "def apply_scaling(x: float) -> float:\n",
    "    return x * 0.000001\n",
    "\n",
    "def add_offset(x):\n",
    "    return x + 1.2345\n",
    "\n",
    "hamburg_scale = geodb.load_collection('openeo~pop_hamburg')\n",
    "hamburg_scale = hamburg_scale.apply(lambda x: apply_scaling(x))\n",
    "hamburg_scale.download('./hamburg_scaled.json', 'GeoJSON')\n",
    "\n",
    "gdf = geopandas.read_file('./hamburg_scaled.json')\n",
    "gdf[['id', 'geometry', 'population', 'date']]"
   ],
   "metadata": {
    "collapsed": false
   },
   "id": "df0c0de2f826109a"
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3 (ipykernel)",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.9.16"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
